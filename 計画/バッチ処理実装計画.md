# バッチ処理実装計画

## 概要
大量のPythonファイルを効率的に処理するためのバッチ処理機能の実装計画です。

## 実装すべきモジュール

### 1. batch_processor.py - バッチ処理エンジン

#### BatchProcessor クラス
```python
class BatchProcessor:
    def __init__(self, config: ProcessingConfig, parallel_config: ParallelConfig):
        self.config = config
        self.parallel_config = parallel_config
        self.stats_collector = StatsCollector()
    
    def process_files(self, file_paths: List[str]) -> BatchResult:
        """ファイル一括処理（同期版）"""
        
    def process_files_streaming(self, file_paths: List[str], 
                              chunk_size: int = 50) -> Iterator[ProcessResult]:
        """ストリーミング処理（メモリ効率重視）"""
        
    def process_directory(self, directory: str, 
                         pattern: str = "**/*.py") -> BatchResult:
        """ディレクトリ内のファイル処理"""
```

### 2. parallel_processor.py - 並列処理

#### ParallelExecutor
```python
class ParallelExecutor:
    def __init__(self, max_workers: int = 4, use_process_pool: bool = True):
        self.max_workers = max_workers
        self.use_process_pool = use_process_pool
        
    def execute_batch(self, tasks: List[ProcessTask]) -> List[ProcessResult]:
        """並列バッチ実行"""
        
    def execute_streaming(self, tasks: Iterator[ProcessTask]) -> Iterator[ProcessResult]:
        """並列ストリーミング実行"""
```

#### ProcessTask
```python
@dataclass
class ProcessTask:
    file_path: str
    source_id: str
    config: ProcessingConfig
    
    def execute(self) -> ProcessResult:
        """タスク実行（ワーカープロセス内）"""
```

### 3. file_scanner.py - ファイル検出・フィルタリング

#### FileScanner
```python
class FileScanner:
    def __init__(self, config: ScanConfig):
        self.config = config
        
    def scan_directory(self, path: str, pattern: str = "**/*.py") -> List[FileInfo]:
        """ディレクトリスキャン"""
        
    def filter_files(self, files: List[str]) -> List[FileInfo]:
        """ファイルフィルタリング"""
        - サイズチェック
        - 拡張子確認
        - .gitignore対応
        - シンボリックリンク処理
```

#### FileInfo
```python
@dataclass
class FileInfo:
    path: str
    size: int
    modified_time: datetime
    is_valid: bool
    skip_reason: Optional[str] = None
```

### 4. progress_tracker.py - 進捗管理

#### ProgressTracker
```python
class ProgressTracker:
    def __init__(self, total_files: int):
        self.total_files = total_files
        self.processed = 0
        self.failed = 0
        self.start_time = time.time()
        
    def update(self, result: ProcessResult) -> None:
        """進捗更新"""
        
    def get_progress(self) -> ProgressInfo:
        """現在の進捗情報取得"""
        
    def estimate_remaining_time(self) -> float:
        """残り時間推定"""
```

### 5. memory_manager.py - メモリ管理

#### MemoryManager
```python
class MemoryManager:
    def __init__(self, max_memory_mb: int = 500):
        self.max_memory_mb = max_memory_mb
        self.current_usage = 0
        
    def check_memory(self) -> bool:
        """メモリ使用量チェック"""
        
    def wait_for_memory(self) -> None:
        """メモリ解放待機"""
        
    def get_optimal_batch_size(self) -> int:
        """最適なバッチサイズ計算"""
```

### 6. error_recovery.py - エラー回復

#### ErrorRecovery
```python
class ErrorRecovery:
    def __init__(self, config: RecoveryConfig):
        self.config = config
        self.failed_files: List[FailedFile] = []
        
    def handle_error(self, task: ProcessTask, error: Exception) -> ProcessResult:
        """エラーハンドリング"""
        
    def retry_failed(self) -> List[ProcessResult]:
        """失敗ファイルの再試行"""
        
    def save_checkpoint(self, processed: List[str]) -> None:
        """チェックポイント保存"""
        
    def resume_from_checkpoint(self) -> List[str]:
        """チェックポイントから再開"""
```

## 実装の重要ポイント

### 1. 並列処理戦略
- **マルチプロセシング**: CPUバウンドなAST解析に最適
- **プロセスプール**: ワーカープロセスの再利用
- **タスクキュー**: 効率的なタスク分配
- **結果キュー**: メモリ効率的な結果収集

### 2. メモリ最適化
- **ストリーミング処理**: 結果を即座に出力
- **チャンク処理**: 大量ファイルを分割
- **ガベージコレクション**: 明示的なメモリ解放
- **メモリ監視**: 使用量の継続的モニタリング

### 3. エラー処理
- **部分的失敗の許容**: 1ファイルの失敗で全体を止めない
- **エラー分類**: 回復可能/不可能なエラーの判別
- **詳細なエラー情報**: デバッグ用の情報保持
- **再試行メカニズム**: 一時的エラーへの対応

### 4. 進捗管理
- **リアルタイム更新**: 処理状況の可視化
- **ETA計算**: 残り時間の推定
- **統計情報収集**: 処理速度、成功率など
- **ログ出力**: 詳細な処理ログ

## パフォーマンス目標

### 処理速度
- 単一ファイル: 平均100ms以内
- バッチ処理: 300ファイル/10分以内
- 並列度: CPUコア数に応じて自動調整

### メモリ使用量
- ピーク時: 500MB以下
- 平均: 200MB以下
- ファイルあたり: 2MB以下

### スケーラビリティ
- 最大10,000ファイルまで対応
- ストリーミング処理で無制限対応可能

## 実装スケジュール

### Week 2 - Phase 2 前半
1. **Day 1**: FileScanner, ProgressTracker実装
2. **Day 2**: BatchProcessor基本実装
3. **Day 3**: ParallelExecutor実装

### Week 2 - Phase 2 後半
4. **Day 4**: MemoryManager実装
5. **Day 5**: ErrorRecovery実装
6. **Day 6-7**: 統合テスト、最適化

## テスト戦略

### 単体テスト
- 各コンポーネントの独立テスト
- モックを使用した並列処理テスト
- エラーケースの網羅的テスト

### 統合テスト
- 実際のPythonプロジェクトでのテスト
- 大規模データセット（1000+ファイル）
- メモリリークテスト
- 並列処理の正確性検証

### パフォーマンステスト
- ベンチマーク測定
- プロファイリング
- ボトルネック特定
- 最適化効果の検証