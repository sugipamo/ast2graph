# データ構造実装計画

## 概要
ast2graphで使用するすべてのデータ構造の定義と実装計画です。

## 実装すべきデータ構造

### 1. models.py - 基本データクラス

#### ASTGraphNode
```python
@dataclass
class ASTGraphNode:
    id: str                    # UUID4形式
    node_type: str            # AST種別（ast.AST.__class__.__name__）
    value: Optional[str]      # ノード値（変数名、関数名等）
    lineno: int              # 行番号
    col_offset: int          # カラム位置
    end_lineno: Optional[int] # 終了行番号
    end_col_offset: Optional[int] # 終了カラム位置
    source_id: str           # ソースファイル識別子
    metadata: Dict[str, Any] = field(default_factory=dict)
```

#### ASTGraphEdge
```python
@dataclass
class ASTGraphEdge:
    source_id: str           # 源ノードID
    target_id: str           # 先ノードID
    edge_type: EdgeType      # エッジ種別
    properties: Dict[str, Any] = field(default_factory=dict)
    order: Optional[int] = None  # 実行順序（NEXTエッジ用）
```

#### EdgeType
```python
class EdgeType(Enum):
    CHILD = "CHILD"                    # 親子関係
    NEXT = "NEXT"                      # 実行順序
    DEPENDS_ON = "DEPENDS_ON"          # 依存関係
    CALLS = "CALLS"                    # 関数呼び出し
    DEFINES = "DEFINES"                # 定義関係
    REFERENCES = "REFERENCES"          # 参照関係
```

### 2. graph_structure.py - グラフ管理クラス

#### GraphStructure
```python
@dataclass
class GraphStructure:
    nodes: Dict[str, ASTGraphNode]     # ノードID -> ノード
    edges: List[ASTGraphEdge]          # エッジリスト
    source_info: SourceInfo            # ソース情報
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def add_node(self, node: ASTGraphNode) -> None
    def add_edge(self, edge: ASTGraphEdge) -> None
    def get_node(self, node_id: str) -> Optional[ASTGraphNode]
    def get_edges_from(self, node_id: str) -> List[ASTGraphEdge]
    def get_edges_to(self, node_id: str) -> List[ASTGraphEdge]
    def validate(self) -> List[str]  # 検証エラーのリスト
```

#### SourceInfo
```python
@dataclass
class SourceInfo:
    source_id: str              # ソースファイル識別子（UUID）
    file_path: str             # ファイルパス
    file_hash: str             # ファイルハッシュ（SHA256）
    parsed_at: datetime        # 解析日時
    encoding: str = "utf-8"    # エンコーディング
    line_count: int = 0        # 行数
    size_bytes: int = 0        # ファイルサイズ
```

### 3. batch_types.py - バッチ処理用データ型

#### ProcessResult
```python
@dataclass
class ProcessResult:
    source_id: str
    file_path: str
    status: ProcessStatus
    graph: Optional[GraphStructure] = None
    error: Optional[ProcessError] = None
    stats: ProcessStats = field(default_factory=ProcessStats)
```

#### ProcessStatus
```python
class ProcessStatus(Enum):
    SUCCESS = "SUCCESS"
    PARTIAL = "PARTIAL"      # 部分的成功
    FAILED = "FAILED"
    SKIPPED = "SKIPPED"      # スキップ（非Pythonファイル等）
```

#### ProcessError
```python
@dataclass
class ProcessError:
    error_type: str          # エラー種別
    message: str            # エラーメッセージ
    line_no: Optional[int] = None
    details: Dict[str, Any] = field(default_factory=dict)
```

#### ProcessStats
```python
@dataclass
class ProcessStats:
    node_count: int = 0      # ノード数
    edge_count: int = 0      # エッジ数
    parse_time_ms: float = 0.0
    build_time_ms: float = 0.0
    memory_usage_mb: float = 0.0
```

#### BatchResult
```python
@dataclass
class BatchResult:
    total_files: int
    successful: int
    failed: int
    results: List[ProcessResult]
    total_time_seconds: float
    peak_memory_mb: float
```

### 4. config.py - 設定データ型

#### ProcessingConfig
```python
@dataclass
class ProcessingConfig:
    max_file_size_mb: int = 10          # 最大ファイルサイズ
    max_nodes_per_file: int = 50000     # ファイルあたり最大ノード数
    timeout_seconds: int = 30           # タイムアウト
    encoding: str = "utf-8"             # デフォルトエンコーディング
    include_docstrings: bool = True     # docstringを含めるか
    include_comments: bool = False      # コメントを含めるか
    follow_imports: bool = False        # インポートを追跡するか
```

#### ParallelConfig
```python
@dataclass
class ParallelConfig:
    max_workers: int = 4               # 最大ワーカー数
    chunk_size: int = 50              # チャンクサイズ
    queue_size: int = 100             # キューサイズ
    use_process_pool: bool = True     # プロセスプールを使うか
```

## 実装における考慮事項

### 1. イミュータビリティ
- dataclassの`frozen=True`オプションの検討
- 変更が必要な場合は新しいインスタンスを作成

### 2. バリデーション
- `__post_init__`でのフィールド検証
- UUID形式の検証
- 必須フィールドの存在確認

### 3. シリアライゼーション
- JSON変換のためのカスタムエンコーダー
- datetime、Enum型の適切な変換
- 循環参照の回避

### 4. メモリ効率
- 大規模グラフでのメモリ使用量最適化
- 遅延読み込みの検討
- 不要なデータの削除

### 5. 型安全性
- 型ヒントの完全な実装
- mypyでの型チェック対応
- ジェネリクスの適切な使用

## 実装手順

1. **基本データクラスの定義**（Day 1）
   - models.py の実装
   - 基本的なバリデーション

2. **グラフ構造の実装**（Day 2）
   - graph_structure.py の実装
   - グラフ操作メソッド

3. **バッチ処理型の実装**（Day 3）
   - batch_types.py の実装
   - 統計情報の計算

4. **設定管理の実装**（Day 4）
   - config.py の実装
   - 設定の読み込み/検証

## テスト計画
- 各データクラスの単体テスト
- シリアライゼーション/デシリアライゼーションテスト
- 大規模データでのメモリ使用量テスト
- エッジケースの検証