# 性能最適化計画

## 概要
ast2graphの性能を最大化し、大規模プロジェクトでも効率的に動作するための最適化計画です。

## 最適化対象と目標

### パフォーマンス目標
- **処理時間**: 300ファイル/10分以内
- **メモリ使用量**: ピーク時500MB以下
- **スループット**: 30ファイル/分以上
- **レイテンシ**: 単一ファイル100ms以内

## 最適化戦略

### 1. AST解析の最適化

#### 1.1 パーサーキャッシュ
```python
class ASTCache:
    def __init__(self, max_size: int = 1000):
        self.cache = LRUCache(max_size)
        
    def get_or_parse(self, source_code: str, file_hash: str) -> ast.AST:
        if file_hash in self.cache:
            return self.cache[file_hash]
        
        parsed = ast.parse(source_code)
        self.cache[file_hash] = parsed
        return parsed
```

#### 1.2 部分的AST解析
- 必要なノードタイプのみ解析
- 深さ制限付き走査
- 大規模ファイルの分割解析

### 2. メモリ最適化

#### 2.1 ノード情報の最小化
```python
class CompactNode:
    """メモリ効率的なノード表現"""
    __slots__ = ['id', 'type', 'value', 'line', 'col', 'source_id']
    
    def __init__(self, node: ASTGraphNode):
        self.id = node.id
        self.type = intern(node.node_type)  # 文字列インターン化
        self.value = node.value
        self.line = node.lineno
        self.col = node.col_offset
        self.source_id = node.source_id
```

#### 2.2 遅延評価
```python
class LazyGraphBuilder:
    def __init__(self, ast_root: ast.AST):
        self.ast_root = ast_root
        self._nodes = None
        self._edges = None
        
    @property
    def nodes(self) -> Dict[str, ASTGraphNode]:
        if self._nodes is None:
            self._nodes = self._build_nodes()
        return self._nodes
        
    @property
    def edges(self) -> List[ASTGraphEdge]:
        if self._edges is None:
            self._edges = self._build_edges()
        return self._edges
```

#### 2.3 メモリプール
```python
class NodePool:
    """事前割り当てによるメモリ断片化防止"""
    def __init__(self, initial_size: int = 10000):
        self.pool = [ASTGraphNode() for _ in range(initial_size)]
        self.next_index = 0
        
    def allocate(self) -> ASTGraphNode:
        if self.next_index >= len(self.pool):
            self._expand_pool()
        node = self.pool[self.next_index]
        self.next_index += 1
        return node
```

### 3. 並列処理の最適化

#### 3.1 ワークスティーリング
```python
class WorkStealingExecutor:
    """動的負荷分散による並列処理"""
    def __init__(self, num_workers: int):
        self.queues = [deque() for _ in range(num_workers)]
        self.workers = []
        
    def steal_work(self, worker_id: int) -> Optional[ProcessTask]:
        # 自分のキューが空なら他のワーカーから取得
        for i in range(len(self.queues)):
            if i != worker_id and self.queues[i]:
                return self.queues[i].popleft()
        return None
```

#### 3.2 バッチサイズの動的調整
```python
class AdaptiveBatchProcessor:
    def __init__(self):
        self.batch_size = 50
        self.performance_history = deque(maxlen=10)
        
    def adjust_batch_size(self, last_performance: float):
        self.performance_history.append(last_performance)
        
        if len(self.performance_history) >= 5:
            trend = self._calculate_trend()
            if trend > 0:  # パフォーマンス向上中
                self.batch_size = min(self.batch_size * 1.2, 200)
            elif trend < 0:  # パフォーマンス低下中
                self.batch_size = max(self.batch_size * 0.8, 10)
```

### 4. I/O最適化

#### 4.1 非同期ファイル読み込み
```python
import asyncio
import aiofiles

class AsyncFileReader:
    async def read_files_async(self, file_paths: List[str]) -> List[Tuple[str, str]]:
        tasks = [self._read_file(path) for path in file_paths]
        return await asyncio.gather(*tasks)
        
    async def _read_file(self, path: str) -> Tuple[str, str]:
        async with aiofiles.open(path, 'r', encoding='utf-8') as f:
            content = await f.read()
            return path, content
```

#### 4.2 バッファリング戦略
```python
class BufferedExporter:
    def __init__(self, buffer_size: int = 1000):
        self.buffer = []
        self.buffer_size = buffer_size
        
    def add_result(self, result: ProcessResult):
        self.buffer.append(result)
        if len(self.buffer) >= self.buffer_size:
            self._flush()
            
    def _flush(self):
        # バッチでディスクに書き込み
        pass
```

### 5. アルゴリズム最適化

#### 5.1 訪問済みノードのスキップ
```python
class OptimizedVisitor(ast.NodeVisitor):
    def __init__(self):
        self.visited = set()
        self.visit_count = 0
        
    def visit(self, node):
        node_id = id(node)
        if node_id in self.visited:
            return
            
        self.visited.add(node_id)
        self.visit_count += 1
        
        # 訪問上限チェック
        if self.visit_count > 50000:
            raise NodeLimitExceeded()
            
        super().visit(node)
```

#### 5.2 エッジ生成の最適化
```python
class EdgeBuilder:
    def __init__(self):
        self.edge_cache = {}
        
    def create_edge(self, source: str, target: str, edge_type: EdgeType) -> ASTGraphEdge:
        # エッジの重複チェック
        edge_key = (source, target, edge_type)
        if edge_key in self.edge_cache:
            return self.edge_cache[edge_key]
            
        edge = ASTGraphEdge(source, target, edge_type)
        self.edge_cache[edge_key] = edge
        return edge
```

### 6. プロファイリングとモニタリング

#### 6.1 パフォーマンスメトリクス
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'parse_time': [],
            'build_time': [],
            'memory_usage': [],
            'node_count': [],
            'edge_count': []
        }
        
    def record_metric(self, metric_name: str, value: float):
        self.metrics[metric_name].append(value)
        
    def get_statistics(self) -> Dict[str, Dict[str, float]]:
        stats = {}
        for metric, values in self.metrics.items():
            if values:
                stats[metric] = {
                    'mean': statistics.mean(values),
                    'median': statistics.median(values),
                    'p95': np.percentile(values, 95),
                    'max': max(values)
                }
        return stats
```

#### 6.2 ボトルネック検出
```python
import cProfile
import pstats

class ProfilerWrapper:
    def __init__(self):
        self.profiler = cProfile.Profile()
        
    def profile_function(self, func, *args, **kwargs):
        self.profiler.enable()
        result = func(*args, **kwargs)
        self.profiler.disable()
        
        # 最も時間のかかった関数を特定
        stats = pstats.Stats(self.profiler)
        stats.sort_stats('cumulative')
        return result, stats
```

## 実装優先順位

### Phase 1: 基本最適化（Week 2）
1. メモリ効率的なデータ構造
2. 基本的なキャッシング
3. シンプルな並列処理

### Phase 2: 高度な最適化（Week 3）
1. 非同期I/O
2. ワークスティーリング
3. 動的バッチサイズ調整

### Phase 3: 微調整（Week 3）
1. プロファイリング結果に基づく最適化
2. メモリプールの実装
3. エッジケースの処理

## ベンチマーク計画

### テストデータセット
- 小規模: 10ファイル（基本性能）
- 中規模: 100ファイル（スケーラビリティ）
- 大規模: 1000ファイル（限界性能）

### 測定項目
- 処理時間（全体、ファイルあたり）
- メモリ使用量（平均、ピーク）
- CPU使用率
- I/O待機時間

### 比較基準
- 最適化前 vs 最適化後
- シングルスレッド vs マルチスレッド
- 同期I/O vs 非同期I/O