# ast2graph データ管理ポリシー設計書

## 1. 概要

ast2graphライブラリにおけるデータの作成・更新・削除に関する統一的なポリシーを定義します。

## 2. 基本方針

### 2.1 データ管理の原則
- **冪等性**: 同一入力での複数回実行で同一結果
- **追跡可能性**: 全データの作成・更新履歴を追跡可能
- **整合性**: ソースコードとグラフデータの整合性維持
- **効率性**: 差分更新による処理効率の最適化

### 2.2 データライフサイクル
```
作成 → 更新 → アーカイブ → 削除
 ↓      ↓       ↓         ↓
新規   変更    非活性化   物理削除
```

## 3. ノードID生成戦略

### 3.1 ID生成方式の比較

| 方式 | メリット | デメリット | 推奨用途 |
|------|---------|-----------|---------|
| **UUID v4** | 衝突なし、分散環境対応 | 長い、可読性低い | デフォルト推奨 |
| **コンテンツハッシュ** | 同一内容で同一ID、重複検知 | 計算コスト | 重複排除が必要な場合 |
| **階層的ID** | 可読性高い、構造表現 | 管理複雑 | デバッグ・分析用途 |

### 3.2 推奨実装: ハイブリッドID

```python
import hashlib
from uuid import uuid4
from typing import Optional

class NodeIDGenerator:
    """ノードID生成クラス"""
    
    @staticmethod
    def generate_ast_node_id(
        source_id: str,
        node_type: str,
        lineno: int,
        col_offset: int,
        content: Optional[str] = None
    ) -> str:
        """
        AST NodeのIDを生成
        形式: {source_id}:{node_type}:{lineno}:{col_offset}:{hash}
        """
        if content:
            # コンテンツベースのハッシュ
            content_hash = hashlib.sha256(content.encode()).hexdigest()[:8]
        else:
            # 位置ベースのハッシュ
            position_str = f"{source_id}:{node_type}:{lineno}:{col_offset}"
            content_hash = hashlib.sha256(position_str.encode()).hexdigest()[:8]
        
        return f"{source_id}:{node_type}:{lineno}:{col_offset}:{content_hash}"
    
    @staticmethod
    def generate_source_id(file_path: str, version: Optional[str] = None) -> str:
        """
        ソースファイルIDを生成
        形式: file:{path_hash}:{version}
        """
        path_hash = hashlib.sha256(file_path.encode()).hexdigest()[:12]
        version = version or datetime.utcnow().strftime("%Y%m%d%H%M%S")
        return f"file:{path_hash}:{version}"
```

## 4. データ更新戦略

### 4.1 更新モード

```python
class UpdateMode(Enum):
    OVERWRITE = "overwrite"      # 既存データを完全置換
    MERGE = "merge"              # 既存データとマージ
    VERSIONED = "versioned"      # バージョン管理
    INCREMENTAL = "incremental"  # 差分のみ更新

class DataUpdateStrategy:
    def __init__(self, mode: UpdateMode = UpdateMode.VERSIONED):
        self.mode = mode
    
    def update_graph(self, source_id: str, new_graph: GraphStructure) -> UpdateResult:
        if self.mode == UpdateMode.OVERWRITE:
            return self._overwrite_strategy(source_id, new_graph)
        elif self.mode == UpdateMode.MERGE:
            return self._merge_strategy(source_id, new_graph)
        elif self.mode == UpdateMode.VERSIONED:
            return self._versioned_strategy(source_id, new_graph)
        else:  # INCREMENTAL
            return self._incremental_strategy(source_id, new_graph)
```

### 4.2 バージョン管理実装

```python
@dataclass
class VersionedNode:
    """バージョン管理されたノード"""
    id: str
    version: int
    created_at: datetime
    updated_at: datetime
    is_current: bool
    previous_version_id: Optional[str]
    
class VersionedGraphManager:
    def create_new_version(self, source_id: str, graph: GraphStructure) -> str:
        """新しいバージョンを作成"""
        version = self._get_next_version(source_id)
        
        with self.driver.session() as session:
            # 既存の現行バージョンを非活性化
            session.run("""
                MATCH (n:ASTNode {source_id: $source_id, is_current: true})
                SET n.is_current = false
            """, source_id=source_id)
            
            # 新バージョンを作成
            for node in graph.nodes:
                versioned_node = VersionedNode(
                    id=node.id,
                    version=version,
                    created_at=datetime.utcnow(),
                    updated_at=datetime.utcnow(),
                    is_current=True,
                    previous_version_id=self._get_previous_version_id(node.id)
                )
                self._create_versioned_node(session, versioned_node)
        
        return f"{source_id}:v{version}"
```

### 4.3 差分検出と増分更新

```python
class DifferentialUpdater:
    """差分検出による効率的な更新"""
    
    def detect_changes(self, old_graph: GraphStructure, new_graph: GraphStructure) -> GraphDiff:
        """グラフの差分を検出"""
        old_nodes = {n.id: n for n in old_graph.nodes}
        new_nodes = {n.id: n for n in new_graph.nodes}
        
        added = [n for id, n in new_nodes.items() if id not in old_nodes]
        removed = [n for id, n in old_nodes.items() if id not in new_nodes]
        modified = [
            (old_nodes[id], new_nodes[id])
            for id in set(old_nodes) & set(new_nodes)
            if self._is_modified(old_nodes[id], new_nodes[id])
        ]
        
        return GraphDiff(
            added_nodes=added,
            removed_nodes=removed,
            modified_nodes=modified,
            stats=DiffStats(
                total_old=len(old_nodes),
                total_new=len(new_nodes),
                added_count=len(added),
                removed_count=len(removed),
                modified_count=len(modified)
            )
        )
    
    def apply_diff(self, graph_diff: GraphDiff) -> UpdateResult:
        """差分を適用"""
        with self.driver.session() as session:
            # 追加
            for node in graph_diff.added_nodes:
                session.run("""
                    CREATE (n:ASTNode $props)
                """, props=node.to_dict())
            
            # 更新
            for old_node, new_node in graph_diff.modified_nodes:
                session.run("""
                    MATCH (n:ASTNode {id: $id})
                    SET n += $props
                    SET n.updated_at = datetime()
                """, id=old_node.id, props=new_node.to_dict())
            
            # 削除（論理削除）
            for node in graph_diff.removed_nodes:
                session.run("""
                    MATCH (n:ASTNode {id: $id})
                    SET n.deleted_at = datetime()
                    SET n.is_deleted = true
                """, id=node.id)
```

## 5. データ削除ポリシー

### 5.1 削除戦略

```python
class DeletionPolicy(Enum):
    SOFT_DELETE = "soft"      # 論理削除（削除フラグ）
    ARCHIVE = "archive"       # アーカイブテーブルへ移動
    HARD_DELETE = "hard"      # 物理削除

class DataDeletionManager:
    def __init__(self, policy: DeletionPolicy = DeletionPolicy.SOFT_DELETE):
        self.policy = policy
    
    def delete_source_data(self, source_id: str) -> DeletionResult:
        """ソースファイルのデータを削除"""
        
        if self.policy == DeletionPolicy.SOFT_DELETE:
            return self._soft_delete(source_id)
        elif self.policy == DeletionPolicy.ARCHIVE:
            return self._archive_and_delete(source_id)
        else:  # HARD_DELETE
            return self._hard_delete(source_id)
    
    def _soft_delete(self, source_id: str) -> DeletionResult:
        """論理削除"""
        with self.driver.session() as session:
            result = session.run("""
                MATCH (n:ASTNode {source_id: $source_id})
                SET n.deleted_at = datetime()
                SET n.is_deleted = true
                RETURN count(n) as deleted_count
            """, source_id=source_id)
            
            deleted_count = result.single()["deleted_count"]
            return DeletionResult(
                source_id=source_id,
                deleted_count=deleted_count,
                deletion_type="soft",
                timestamp=datetime.utcnow()
            )
```

### 5.2 データ保持期間

```python
class RetentionPolicy:
    """データ保持ポリシー"""
    
    DEFAULT_RETENTION_DAYS = {
        "active": None,          # 無期限
        "deleted": 30,           # 30日
        "archived": 365,         # 1年
        "version_history": 90    # 90日
    }
    
    def cleanup_expired_data(self):
        """期限切れデータのクリーンアップ"""
        
        # 削除済みデータのクリーンアップ
        cutoff_date = datetime.utcnow() - timedelta(days=self.DEFAULT_RETENTION_DAYS["deleted"])
        
        with self.driver.session() as session:
            session.run("""
                MATCH (n:ASTNode {is_deleted: true})
                WHERE n.deleted_at < $cutoff_date
                DETACH DELETE n
            """, cutoff_date=cutoff_date)
            
            # 古いバージョンのクリーンアップ
            version_cutoff = datetime.utcnow() - timedelta(days=self.DEFAULT_RETENTION_DAYS["version_history"])
            session.run("""
                MATCH (n:ASTNode {is_current: false})
                WHERE n.created_at < $cutoff_date
                AND NOT EXISTS {
                    MATCH (current:ASTNode {is_current: true})
                    WHERE current.previous_version_id = n.id
                }
                DETACH DELETE n
            """, cutoff_date=version_cutoff)
```

## 6. 重複データ処理

### 6.1 重複検出

```python
class DuplicateHandler:
    """重複データの検出と処理"""
    
    def detect_duplicates(self, graph: GraphStructure) -> List[DuplicateGroup]:
        """重複ノードを検出"""
        
        # コンテンツハッシュでグループ化
        hash_groups = defaultdict(list)
        for node in graph.nodes:
            content_hash = self._calculate_content_hash(node)
            hash_groups[content_hash].append(node)
        
        # 重複グループを抽出
        duplicates = []
        for hash_val, nodes in hash_groups.items():
            if len(nodes) > 1:
                duplicates.append(DuplicateGroup(
                    content_hash=hash_val,
                    nodes=nodes,
                    count=len(nodes)
                ))
        
        return duplicates
    
    def handle_duplicates(self, duplicates: List[DuplicateGroup], strategy: str = "merge"):
        """重複を処理"""
        
        if strategy == "merge":
            # 重複をマージ（最初のノードを保持）
            for group in duplicates:
                primary = group.nodes[0]
                for duplicate in group.nodes[1:]:
                    self._merge_nodes(primary, duplicate)
                    
        elif strategy == "keep_all":
            # 全て保持（関連付けのみ）
            for group in duplicates:
                self._link_duplicates(group.nodes)
```

## 7. データ整合性チェック

### 7.1 整合性検証

```python
class IntegrityChecker:
    """データ整合性の検証"""
    
    def validate_graph_integrity(self, source_id: str) -> IntegrityReport:
        """グラフの整合性を検証"""
        
        checks = {
            "orphaned_nodes": self._check_orphaned_nodes(source_id),
            "circular_dependencies": self._check_circular_dependencies(source_id),
            "missing_relationships": self._check_missing_relationships(source_id),
            "duplicate_ids": self._check_duplicate_ids(source_id),
            "version_consistency": self._check_version_consistency(source_id)
        }
        
        issues = [issue for check, issue in checks.items() if issue]
        
        return IntegrityReport(
            source_id=source_id,
            is_valid=len(issues) == 0,
            issues=issues,
            checked_at=datetime.utcnow()
        )
    
    def _check_orphaned_nodes(self, source_id: str) -> Optional[IntegrityIssue]:
        """孤立ノードをチェック"""
        result = self.driver.session().run("""
            MATCH (n:ASTNode {source_id: $source_id})
            WHERE NOT EXISTS {
                MATCH (n)-[]-()
            }
            RETURN count(n) as orphan_count, collect(n.id)[..10] as sample_ids
        """, source_id=source_id).single()
        
        if result["orphan_count"] > 0:
            return IntegrityIssue(
                type="orphaned_nodes",
                severity="warning",
                count=result["orphan_count"],
                details={"sample_ids": result["sample_ids"]}
            )
        return None
```

### 7.2 自動修復

```python
class DataRepairer:
    """データの自動修復"""
    
    def auto_repair(self, integrity_report: IntegrityReport) -> RepairResult:
        """整合性問題を自動修復"""
        
        repairs = []
        for issue in integrity_report.issues:
            if issue.type == "orphaned_nodes" and issue.severity == "warning":
                repair = self._repair_orphaned_nodes(issue)
                repairs.append(repair)
            elif issue.type == "duplicate_ids" and issue.severity == "error":
                repair = self._repair_duplicate_ids(issue)
                repairs.append(repair)
        
        return RepairResult(
            total_issues=len(integrity_report.issues),
            repaired=len([r for r in repairs if r.success]),
            failed=len([r for r in repairs if not r.success]),
            repairs=repairs
        )
```

## 8. トランザクション管理

### 8.1 トランザクションポリシー

```python
class TransactionManager:
    """トランザクション管理"""
    
    def __init__(self, driver, isolation_level: str = "READ_COMMITTED"):
        self.driver = driver
        self.isolation_level = isolation_level
    
    def execute_in_transaction(self, operations: List[Operation]) -> TransactionResult:
        """複数操作をトランザクション内で実行"""
        
        with self.driver.session() as session:
            try:
                def work(tx):
                    results = []
                    for op in operations:
                        result = op.execute(tx)
                        results.append(result)
                    return results
                
                results = session.write_transaction(work)
                
                return TransactionResult(
                    success=True,
                    results=results,
                    operations_count=len(operations)
                )
                
            except Exception as e:
                logger.error(f"Transaction failed: {e}")
                return TransactionResult(
                    success=False,
                    error=str(e),
                    operations_count=len(operations)
                )
```

## 9. 監査とコンプライアンス

### 9.1 監査ログ

```python
class AuditLogger:
    """データ操作の監査ログ"""
    
    def log_data_operation(self, operation: DataOperation):
        """データ操作を記録"""
        
        audit_entry = {
            "operation_id": str(uuid4()),
            "operation_type": operation.type,  # CREATE, UPDATE, DELETE
            "source_id": operation.source_id,
            "user": operation.user or "system",
            "timestamp": datetime.utcnow().isoformat(),
            "affected_nodes": operation.affected_nodes_count,
            "metadata": operation.metadata
        }
        
        # Neo4jに監査ログを保存
        with self.driver.session() as session:
            session.run("""
                CREATE (a:AuditLog $props)
            """, props=audit_entry)
```

## 10. パフォーマンス最適化

### 10.1 インデックス戦略

```python
class IndexManager:
    """インデックス管理"""
    
    REQUIRED_INDEXES = [
        ("ASTNode", "id"),
        ("ASTNode", "source_id"),
        ("ASTNode", "node_type"),
        ("ASTNode", ["source_id", "is_current"]),
        ("AuditLog", "timestamp")
    ]
    
    def ensure_indexes(self):
        """必要なインデックスを作成"""
        
        with self.driver.session() as session:
            for label, properties in self.REQUIRED_INDEXES:
                if isinstance(properties, list):
                    # 複合インデックス
                    props_str = ", ".join([f"n.{p}" for p in properties])
                    session.run(f"""
                        CREATE INDEX IF NOT EXISTS
                        FOR (n:{label})
                        ON ({props_str})
                    """)
                else:
                    # 単一インデックス
                    session.run(f"""
                        CREATE INDEX IF NOT EXISTS
                        FOR (n:{label})
                        ON (n.{properties})
                    """)
```

## 11. 設定例

### 11.1 推奨設定

```python
# 開発環境
DEVELOPMENT_CONFIG = {
    "update_mode": UpdateMode.OVERWRITE,
    "deletion_policy": DeletionPolicy.HARD_DELETE,
    "id_generation": "uuid",
    "enable_versioning": False,
    "enable_audit": False
}

# 本番環境
PRODUCTION_CONFIG = {
    "update_mode": UpdateMode.VERSIONED,
    "deletion_policy": DeletionPolicy.SOFT_DELETE,
    "id_generation": "content_hash",
    "enable_versioning": True,
    "enable_audit": True,
    "retention_days": {
        "deleted": 90,
        "version_history": 180
    }
}
```

この設計により、ast2graphライブラリは柔軟で堅牢なデータ管理を実現します。